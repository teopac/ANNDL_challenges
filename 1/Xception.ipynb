{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Xception.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6y5U_Ah0nc-d"},"source":["# Xception\n","The following notebook implements the best transfer learning architecture we were able to achieve. Images are rescaled to 299x299 and data augmentation is applied on the training set with the best hyperparameters obtained after a parameter tuning study. The following table summarizes the hyperparameters of the network:\n","\n","| Hyperparameter <img width=100/> | Value <img width=50/>|\n","|:-|:-:|\n","| batch_size <img width=100/> | 16 <img width=50/> |\n","| img_h <img width=100/> | 299  <img width=50/> |\n","| img_w <img width=100/> | 299 <img width=50/> |\n","| learning_rate  <img width=100/> | 0.0001 <img width=50/> |\n","\n","The model obtained is compiled with __Adam__ optimizer and the accuracy __metric__. Finally, the techniques used in order to face __overfitting__ are:\n","* __Early Stopping__: called with ```(monitor='val_loss', patience=5)```\n","* __Weight Decay__: on all the layers of the architecture, both on Xception's and the last dense ones"]},{"cell_type":"code","metadata":{"id":"TDnikYeHoeVS"},"source":["import os\n","import tensorflow as tf\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q1pwTm_6oifY"},"source":["## Directories Initialization\n","The notebook can be run independently referring to the __base__ folder created in the following cells. In colab, once mounted drive and unzipped the dataset, we can continue the whole experiment in the base directory only. Remember to assign to the ```zip_path``` variable the path to your MaskDataset.zip."]},{"cell_type":"code","metadata":{"id":"i4iJFWKvonCf"},"source":["# DIRECTORIES\n","zip_path = 'INSERT_HERE_ZIP_PATH'\n","base_dir = '/content/base'\n","if not os.path.exists(base_dir):\n","  os.makedirs(base_dir)\n","\n","os.chdir(base_dir)\n","cwd = os.getcwd()\n","\n","# checkpointing and results directories\n","exps_dir = os.path.join(cwd, 'Checkpoints')\n","if not os.path.exists(exps_dir):\n","  os.makedirs(exps_dir)\n","\n","res_dir = os.path.join(cwd, 'Results')\n","if not os.path.exists(res_dir):\n","  os.makedirs(res_dir)\n","\n","# dataset directories\n","dataset_dir = os.path.join(cwd, 'MaskDataset')\n","training_dir = os.path.join(dataset_dir, 'train')\n","validation_dir = os.path.join(dataset_dir, 'val')\n","test_dir = os.path.join(dataset_dir, 'test')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-UHwdaioxsV"},"source":["### Directory Structure\n","\n","Now we have to mount drive and unzip the dataset. Finally the directories will be structured in the following way:\n","    \n","    - base/\n","      - Checkpoints/\n","      - Results/\n","      - MaskDataset/\n","          - test/\n","              - img1, img2, …, imgN\n","          - train/\n","              - 0_none/\n","                  - img1, img2, …, imgN\n","              - 1_all/\n","                  - img1, img2, …, imgN\n","              - 2_some/ \n","                  - img1, img2, ... , imgN\n","          - val/\n","              - 0_none/\n","                  - img1, img2, …, imgN\n","              - 1_all/\n","                  - img1, img2, …, imgN\n","              - 2_some/ \n","                  - img1, img2, ... , imgN"]},{"cell_type":"code","metadata":{"id":"mspmD72Eo2Ib"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTzq25gJpA4M"},"source":["# MaskDataset unzipping, provide the path of MaskDataset.zip in zip_path\n","!unzip {zip_path}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JUkUbddVpMqZ"},"source":["## Network implementation\n","We now have to realize the network, first we decide the hyperparameters, apply data preprocessing and build the data generators to train the network. Then, we encode the architecture, compile the model and finally train it."]},{"cell_type":"markdown","metadata":{"id":"c4lBNoBApP38"},"source":["### Hyperparameters"]},{"cell_type":"code","metadata":{"id":"OCPX_XY-bdWi"},"source":["# SEED setting\n","SEED = 1234\n","tf.random.set_seed(SEED)\n","\n","# hyperparameters\n","bs = 16\n","img_h = 299\n","img_w = 299\n","lr = 1e-4\n","\n","# model features\n","num_classes=3\n","model_name = 'XC_REG'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JnaoRcUspucD"},"source":["### Data Augmentation"]},{"cell_type":"code","metadata":{"id":"usOY3Hdx0OtX"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","prepr_func = tf.keras.applications.xception.preprocess_input\n","\n","apply_data_augmentation = True\n","\n","# Create training ImageDataGenerator object\n","if apply_data_augmentation:\n","    train_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        width_shift_range=10,\n","                                        height_shift_range=10,\n","                                        zoom_range=0.3,\n","                                        shear_range=0.3,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=False,\n","                                        fill_mode='constant',\n","                                        cval=0.0,\n","                                        preprocessing_function=prepr_func)  # to apply Xcpetion normalization\n","else:\n","    train_data_gen = ImageDataGenerator(preprocessing_function=prepr_func)\n","\n","# Create validation ImageDataGenerator object\n","valid_data_gen = ImageDataGenerator(preprocessing_function=prepr_func)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iw6-AQP_qCXO"},"source":["### Data Management"]},{"cell_type":"code","metadata":{"id":"WnaXvthL0Otb"},"source":["# GENERATORS\n","\n","# Training\n","training_dir = os.path.join(dataset_dir, 'train')\n","train_gen = train_data_gen.flow_from_directory(training_dir,\n","                                               batch_size=bs, \n","                                               class_mode='categorical',\n","                                               shuffle=True,\n","                                               target_size=(img_h, img_w),\n","                                               seed=SEED)\n","\n","# Validation\n","validation_dir = os.path.join(dataset_dir, 'val')\n","valid_gen = valid_data_gen.flow_from_directory(validation_dir,\n","                                               batch_size=bs, \n","                                               class_mode='categorical',\n","                                               shuffle=False,\n","                                               target_size=(img_h, img_w),\n","                                               seed=SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SrXvKly0Otf"},"source":["# DATASET OBJECTS\n","\n","# Training\n","train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","\n","train_dataset = train_dataset.repeat()\n","\n","# Validation\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","\n","valid_dataset = valid_dataset.repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uIjbmJ19qV0E"},"source":["### Model Architecture\n","The architecture of the transfer learning model loads the Xception model provided by Keras and on top of it, it applies three dense layers. Regularization of the kernel weights is applied both on all the layers of Xception and also in the last dense layers. To do so we used the L2 normalization function providing as argument 0.0001. In the end we find the last dense layer with a number of units corresponding to the number of our classes, which allows to make the classification."]},{"cell_type":"code","metadata":{"id":"Mwk5LxY-0Otj"},"source":["# Xception Loading\n","xc = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(img_h, img_w,3))\n","xc.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEA4xycZsDCN"},"source":["### Regularization\n","Regularizers were tested for kernels, activities and biases. In the end the most effective one was the __kernel_reg__."]},{"cell_type":"code","metadata":{"id":"-7jHWWodiPKB"},"source":["# REGULARIZERS\n","def kernel_reg(model, regularizer=tf.keras.regularizers.l2(0.0001)):\n","    for layer in model.layers:\n","        for attr in ['kernel_regularizer']:\n","            if hasattr(layer, attr):\n","              setattr(layer, attr, regularizer)\n","\n","def activity_reg(model, regularizer=tf.keras.regularizers.l2(0.0001)):\n","    for layer in model.layers:\n","        for attr in ['activity_regularizer']:\n","            if hasattr(layer, attr):\n","              setattr(layer, attr, regularizer)\n","\n","def bias_reg(model, regularizer=tf.keras.regularizers.l2(0.0001)):\n","    for layer in model.layers:\n","        for attr in ['bias_regularizer']:\n","            if hasattr(layer, attr):\n","              setattr(layer, attr, regularizer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U7n1EH-pskLH"},"source":["### Architecture"]},{"cell_type":"code","metadata":{"id":"p_Sw7OA30Ots","scrolled":true},"source":["import tempfile\n","\n","# REGULARIZE\n","kernel_reg(xc)\n","\n","model_json = xc.to_json()\n","tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n","xc.save_weights(tmp_weights_path)\n","xc = tf.keras.models.model_from_json(model_json)\n","xc.load_weights(tmp_weights_path, by_name=True)\n","\n","# MODEL\n","model = tf.keras.Sequential()\n","\n","# add first Xception and the missing GAP\n","model.add(xc)\n","model.add(tf.keras.layers.GlobalAveragePooling2D())\n","\n","# finally the dense layers\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n","model.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n","model.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n","\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","# Visualize created model as a table\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jxt4_VaOsxMy"},"source":["### Model Compile"]},{"cell_type":"code","metadata":{"id":"RDfs6zWP0Otw"},"source":["# loss function\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","# optimizer\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","# metrics\n","metrics = ['accuracy']\n","\n","# compile model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vbgiL2-CtFKQ"},"source":["### Training with Callbacks\n","The following callbacks are used during training for model checkpointing, data visualization and early stopping. "]},{"cell_type":"code","metadata":{"id":"dcY5pIOk0Ot0","scrolled":true},"source":["from datetime import datetime\n","\n","# Experiments dir\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","\n","if not os.path.exists(exp_dir):\n","    os.makedirs(exp_dir)\n","\n","callbacks = []\n","\n","# Visualize Learning on Tensorboard\n","# ---------------------------------\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","    \n","# By default shows losses and metrics for both training and validation\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)\n","callbacks.append(tb_callback)\n","\n","# Model checkpoint\n","# ---------------\n","ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","\n","if not os.path.exists(ckpt_dir):\n","    os.makedirs(ckpt_dir)\n","\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n","                                                   save_weights_only=False,\n","                                                   save_best_only=True)\n","\n","callbacks.append(ckpt_callback)\n","\n","# Early Stopping\n","# --------------\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","    callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nNz-K9Mitkn7"},"source":["### Model Training"]},{"cell_type":"code","metadata":{"id":"1KTzoYAwtj8c"},"source":["# TRAINING\n","model.fit(x=train_dataset,\n","          epochs=100,  #### set repeat in training dataset\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xDBCY2RP0Ot3"},"source":["## Model Testing\n","Once the model is trained we can test it by calling the predict method on the images contained in the test dataset. In the end we build the .csv file used for the submissions."]},{"cell_type":"code","metadata":{"id":"0u3fsqSxY4bI"},"source":["def create_csv(results, model_name):\n","    csv_fname = model_name + '_results_'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(res_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZBbHpn601mI"},"source":["from PIL import Image\n","\n","image_filenames = next(os.walk(test_dir + '/test'))[2]\n","\n","results = {}\n","for image_name in image_filenames:\n","  img = Image.open(test_dir + '/test/' + image_name).convert('RGB')\n","  img = img.resize((img_h, img_w))\n","\n","  img_array = np.array(img)\n","  img_array = img_array * 1. / 255\n","  img_array = np.expand_dims(img_array, 0)\n","\n","  predictions = model.predict(img_array)\n","  predicted_class = np.argmax(predictions, axis=-1)\n","\n","  predicted_class = predicted_class[0]\n","  results[image_name] = predicted_class\n","\n","create_csv(results, model_name)"],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"UNET_PEAD_MAIS","provenance":[{"file_id":"1CJakdKDkAjI5B9iR2plM_93V5lwcjd5V","timestamp":1609065830060},{"file_id":"1_yVdTV-ka6p8LU8AIay9RatbdBxqd6U4","timestamp":1608576770230},{"file_id":"1Jxt0bOMHHWecjWVmVtBUZptN751-vvcr","timestamp":1608574922325},{"file_id":"1zTgypN1dYtxbnsvQPEtURLgCqyfuuHN6","timestamp":1608400918342},{"file_id":"1-hcaDu6xYY_68sHm1vFbfoKSeqU-ykQ_","timestamp":1608300815469},{"file_id":"1KWAZ1z31U5ZxFAtw5yjB3EhMbUl9cuCj","timestamp":1607465245834}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3v3vh02lHYYL"},"source":["This is the architecture that gave us the best result in Pead Mais. \r\n","\r\n","It is a very simple U-Net, with less than a million parameters. It has been trained with squared tiles of 512x512 pixels, as described in our report.\r\n","\r\n","Here, filtered tiles are used. You need to first run the filter_tiles.py script in the \"script\" folder.\r\n","\r\n","\r\n","Note that this notebook is very similar to notebook unet_ADD_SKIP, so please refer to that one for commented code."]},{"cell_type":"code","metadata":{"id":"hb-zN1bbe687"},"source":[" from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mQ3XnuTye_vO"},"source":["import os\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","SEED = 1234\n","img_w = 512\n","img_h = 512\n","bs = 8\n","lr = 1e-3\n","num_epochs = 100\n","patience = 7\n","num_classes = 3\n","\n","\n","# kfold\n","val_split_perc = 0.2\n","k = 5\n","enable_kfold = True\n","if not enable_kfold:\n","  k = int(1 / val_split_perc)\n","\n","\n","# boolean flags\n","# what you want to include in training phase\n","bool_arr = []\n","bool_arr.append([False, \"Bipbip\", \"Haricot\", \".jpg\"])\n","bool_arr.append([False, \"Bipbip\", \"Mais\", \".jpg\"])\n","bool_arr.append([False, \"Pead\", \"Haricot\", \".jpg\"])\n","bool_arr.append([True, \"Pead\", \"Mais\", \".jpg\"])\n","bool_arr.append([False, \"Roseau\", \"Haricot\", \".png\"])\n","bool_arr.append([False, \"Roseau\", \"Mais\", \".png\"])\n","bool_arr.append([False, \"Weedelec\", \"Haricot\", \".jpg\"])\n","bool_arr.append([False, \"Weedelec\", \"Mais\", \".jpg\"])\n","\n","# what you want to test\n","# to generate a valid json though, you need to include all of these\n","bool_arr_test = []\n","bool_arr_test.append([True, \"Bipbip\", \"Haricot\", \".jpg\"])\n","bool_arr_test.append([True, \"Bipbip\", \"Mais\", \".jpg\"])\n","bool_arr_test.append([True, \"Pead\", \"Haricot\", \".jpg\"])\n","bool_arr_test.append([True, \"Pead\", \"Mais\", \".jpg\"])\n","bool_arr_test.append([True, \"Roseau\", \"Haricot\", \".png\"])\n","bool_arr_test.append([True, \"Roseau\", \"Mais\", \".png\"])\n","bool_arr_test.append([True, \"Weedelec\", \"Haricot\", \".jpg\"])\n","bool_arr_test.append([True, \"Weedelec\", \"Mais\", \".jpg\"])\n","\n","model_name = 'unet_pead_mais'\n","\n","tf.random.set_seed(SEED) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WacDhwdYfA77"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x43-ArnVfRHA"},"source":["cwd = os.getcwd() # should be /content\n","\n","dataset_version = 'Filtered_Development_Dataset_512'\n","\n","path_to_zip = '/content/drive/My\\ Drive/challenge2/dataset/' + dataset_version + '.zip'\n","\n","if not os.path.exists(os.path.join(cwd, dataset_version)):\n","    !unzip {path_to_zip}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EcsG6HOa6-Fe"},"source":["import pandas as pd\r\n","\r\n","filenames_images = []\r\n","filenames_masks = []\r\n","\r\n","base_folder = os.path.join(cwd, dataset_version, \"Training\")\r\n","\r\n","for i in range(0,8):\r\n","  if bool_arr[i][0]:\r\n","    bf = []\r\n","    base_curr = os.path.join(base_folder, bool_arr[i][1], bool_arr[i][2])\r\n","    fn_images = [x for x in os.listdir(os.path.join(base_curr, \"Images\"))]\r\n","    fn_images.sort()\r\n","    fn_masks = [x for x in os.listdir(os.path.join(base_curr, \"Masks\"))]\r\n","    fn_masks.sort()\r\n","\r\n","    for index, value in enumerate(fn_images):\r\n","      fn_images[index] = os.path.join(base_curr, \"Images\", value)\r\n","\r\n","    for index, value in enumerate(fn_masks):\r\n","      fn_masks[index] = os.path.join(base_curr, \"Masks\", value)\r\n","\r\n","    filenames_images += fn_images\r\n","    filenames_masks += fn_masks\r\n","\r\n","data = pd.DataFrame(columns=[\"images\", \"masks\"])\r\n","data[\"images\"] = filenames_images\r\n","data[\"masks\"] = filenames_masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9IVnZ-QyiWWE"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","prepr_func = tf.keras.applications.vgg16.preprocess_input\n","\n","# Create training ImageDataGenerator object\n","# We need two different generators for images and corresponding masks\n","train_img_data_gen = ImageDataGenerator(rotation_range=30,\n","                                        width_shift_range=10,\n","                                        height_shift_range=10,\n","                                        zoom_range=0.3,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        fill_mode='reflect',                                          \n","                                        rescale=1./255)\n","\n","train_mask_data_gen = ImageDataGenerator(rotation_range=30,\n","                                          width_shift_range=10,\n","                                          height_shift_range=10,\n","                                          zoom_range=0.3,\n","                                          horizontal_flip=True,\n","                                          vertical_flip=True,\n","                                          fill_mode='reflect')\n","\n","# Create validation and test ImageDataGenerator objects\n","valid_img_data_gen = ImageDataGenerator(rescale=1./255)\n","valid_mask_data_gen = ImageDataGenerator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLCOOrE3Vr8F"},"source":["def prepare_target(x_, y_):\r\n","    return x_, (tf.cast(tf.reduce_any(y_ == 0, axis=-1, keepdims=True), tf.float32)*0 + \r\n","                tf.cast(tf.reduce_any(y_ == 124, axis=-1, keepdims=True), tf.float32)*0 + \r\n","                tf.cast(tf.reduce_any(y_ == 255, axis=-1, keepdims=True), tf.float32)*1 + \r\n","                tf.cast(tf.reduce_any(y_ == 67, axis=-1, keepdims=True), tf.float32)*2) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svkxImmWtWTo"},"source":["from tensorflow.keras.layers import *\r\n","\r\n","def upsampleLayer(in_layer, concat_layer, input_size):\r\n","  '''\r\n","  Upsampling (=Decoder) layer building block\r\n","  Parameters\r\n","  ----------\r\n","  in_layer: input layer\r\n","  concat_layer: layer with which to concatenate\r\n","  input_size: input size for convolution\r\n","  '''\r\n","  upsample = Conv2DTranspose(input_size, (2, 2), strides=(2, 2), padding='same')(in_layer) \r\n","  upsample = concatenate([concat_layer, upsample])\r\n","  conv = Conv2D(input_size, (3, 3), activation='relu', padding='same')(upsample)\r\n","  return conv\r\n","\r\n","def create_model(num_classes):\r\n","\r\n","  inputs_1 = tf.keras.Input((img_h, img_w, 3))\r\n","\r\n","  # encoder\r\n","  e1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs_1)\r\n","  e1b = MaxPool2D(pool_size=(2, 2))(e1)\r\n","\r\n","  e2 = Conv2D(64, (3, 3), activation='relu', padding='same')(e1b)\r\n","  e2b = MaxPool2D(pool_size=(2, 2))(e2)\r\n","\r\n","  e3 = Conv2D(128, (3, 3), activation='relu', padding='same')(e2b)\r\n","  e3b = MaxPool2D(pool_size=(2, 2))(e3)\r\n","\r\n","  # bottleneck\r\n","  e4 = Conv2D(256, (3, 3), activation='relu', padding='same')(e3b)\r\n","\r\n","  # decoder\r\n","  d1 = upsampleLayer(in_layer=e4, concat_layer=e3, input_size=128)\r\n","  d2 = upsampleLayer(in_layer=d1, concat_layer=e2, input_size=64)\r\n","  d3 = upsampleLayer(in_layer=d2, concat_layer=e1, input_size=32)\r\n","\r\n","  outputs = Conv2D(num_classes, (1, 1), activation='softmax')(d3)\r\n","\r\n","  model = tf.keras.Model(inputs=inputs_1, outputs=outputs)\r\n","  \r\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPfgobNhW9OE"},"source":["def meanIoU(y_true, y_pred):\r\n","    # get predicted class from softmax\r\n","    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\r\n","\r\n","    per_class_iou = []\r\n","\r\n","    for i in range(1,num_classes): # exclude the background class 0\r\n","      # Get prediction and target related to only a single class (i)\r\n","      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\r\n","      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\r\n","      intersection = tf.reduce_sum(class_true * class_pred)\r\n","      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\r\n","    \r\n","      iou = (intersection + 1e-7) / (union + 1e-7)\r\n","      per_class_iou.append(iou)\r\n","\r\n","    return tf.reduce_mean(per_class_iou)\r\n","\r\n","def cropIoU(y_true, y_pred):\r\n","    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\r\n","    i = 1\r\n","    class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\r\n","    class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\r\n","    intersection = tf.reduce_sum(class_true * class_pred)\r\n","    union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\r\n","    iou = (intersection + 1e-7) / (union + 1e-7)\r\n","    return iou"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NuwoEdYYaw05"},"source":["def display(display_list):\r\n","  plt.figure(figsize=(15, 15))\r\n","\r\n","  title = ['Input Image', 'True Mask', 'Predicted Mask']\r\n","\r\n","  for i in range(len(display_list)):\r\n","    plt.subplot(1, len(display_list), i+1)\r\n","    plt.title(title[i])\r\n","    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\r\n","    plt.axis('off')\r\n","  plt.show()\r\n","\r\n","def create_mask(pred_mask):\r\n","  pred_mask = tf.argmax(pred_mask, axis=-1)\r\n","  pred_mask = pred_mask[..., tf.newaxis]\r\n","  return pred_mask[0]\r\n","\r\n","def show_predictions(dataset=None, num=1):\r\n","  if dataset:\r\n","    for image, mask in dataset.take(num):\r\n","      pred_mask = model.predict(image)\r\n","      display([image[0], mask[0], create_mask(pred_mask)])\r\n","  else:\r\n","    display([train_sample_image, train_sample_mask,\r\n","             create_mask(model.predict(train_sample_image[tf.newaxis, ...]))])\r\n","    display([valid_sample_image, valid_sample_mask,\r\n","             create_mask(model.predict(valid_sample_image[tf.newaxis, ...]))])\r\n","    \r\n","class DisplayCallback(tf.keras.callbacks.Callback):\r\n","  def on_epoch_end(self, epoch, logs=None):\r\n","    #clear_output(wait=True)\r\n","    show_predictions()\r\n","    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGisKIPc93kf"},"source":["def get_callbacks(exp_dir):\r\n","  callbacks = []\r\n","\r\n","  callbacks.append(DisplayCallback())\r\n","\r\n","  ckpt_dir = os.path.join(exp_dir, 'ckpts')\r\n","  if not os.path.exists(ckpt_dir):\r\n","      os.makedirs(ckpt_dir)\r\n","\r\n","  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\r\n","                                                    monitor='val_loss',\r\n","                                                    mode='min', \r\n","                                                    save_weights_only=False,\r\n","                                                    save_best_only=True,\r\n","                                                    verbose=0)  \r\n","  callbacks.append(ckpt_callback)\r\n","\r\n","  # Early Stopping\r\n","  early_stop = True\r\n","  if early_stop:\r\n","      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \r\n","                                                    patience=patience, \r\n","                                                    restore_best_weights=True)\r\n","      callbacks.append(es_callback)\r\n","\r\n","  return callbacks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dFfT5FJXyRh"},"source":["from datetime import datetime\r\n","\r\n","exps_dir = '/content/drive/My Drive/challenge2/Teo/Models'\r\n","if not os.path.exists(exps_dir):\r\n","    os.makedirs(exps_dir)\r\n","\r\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\r\n","\r\n","exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\r\n","if not os.path.exists(exp_dir):\r\n","    os.makedirs(exp_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L5eNdD5J-pVn"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","kfold = KFold(n_splits=k, random_state=SEED, shuffle=True)\r\n","\r\n","loop_iteration = 0\r\n","\r\n","loss_arr = []\r\n","meanIoU_arr = []\r\n","\r\n","for train_index, val_index in kfold.split(X=data[\"images\"], y=data[\"masks\"]):\r\n","  training_data = data.iloc[train_index]\r\n","  validation_data = data.iloc[val_index]\r\n","\r\n","  #creation of the couple of generator for images and masks from training\r\n","  train_img_data_generator = train_img_data_gen.flow_from_dataframe(training_data,\r\n","                                                                    x_col = \"images\",\r\n","                                                                    shuffle = True,\r\n","                                                                    class_mode = None,\r\n","                                                                    target_size=(img_h, img_w),\r\n","                                                                    batch_size=bs,\r\n","                                                                    interpolation=\"nearest\",\r\n","                                                                    seed=SEED)\r\n","  train_mask_data_generator = train_mask_data_gen.flow_from_dataframe(training_data,\r\n","                                                                      x_col = \"masks\",\r\n","                                                                      shuffle = True,\r\n","                                                                      class_mode = None,\r\n","                                                                      target_size=(img_h, img_w),\r\n","                                                                      batch_size=bs,\r\n","                                                                      interpolation=\"nearest\",\r\n","                                                                      seed=SEED)\r\n","  train_gen = zip(train_img_data_generator, train_mask_data_generator)\r\n","\r\n","  #creation of the couple of generators for images and masks for validation  \r\n","  valid_img_data_generator = valid_img_data_gen.flow_from_dataframe(validation_data,\r\n","                                                       x_col = \"images\",\r\n","                                                       shuffle = True,\r\n","                                                       class_mode = None,\r\n","                                                       target_size=(img_h, img_w),\r\n","                                                       batch_size=bs,\r\n","                                                       interpolation=\"nearest\",\r\n","                                                       seed = SEED)\r\n","  valid_mask_data_generator = valid_mask_data_gen.flow_from_dataframe(validation_data, \r\n","                                                      x_col = \"masks\",\r\n","                                                      shuffle = True,\r\n","                                                      class_mode = None,\r\n","                                                      target_size=(img_h, img_w),\r\n","                                                      batch_size=bs,\r\n","                                                      interpolation=\"nearest\",\r\n","                                                      seed = SEED)\r\n","  valid_gen = zip(valid_img_data_generator, valid_mask_data_generator)\r\n","\r\n","  #######################\r\n","\r\n","  train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\r\n","                                               output_types=(tf.float32, tf.float32),\r\n","                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 3]))\r\n","  train_dataset = train_dataset.map(prepare_target)\r\n","  train_dataset = train_dataset.repeat()\r\n","\r\n","  valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \r\n","                                                output_types=(tf.float32, tf.float32),\r\n","                                                output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 3]))\r\n","  valid_dataset = valid_dataset.map(prepare_target)\r\n","  valid_dataset = valid_dataset.repeat()\r\n","\r\n","  for imageBatch, maskBatch in train_dataset.take(1):\r\n","    train_sample_image, train_sample_mask = imageBatch[0], maskBatch[0]\r\n","\r\n","  display([train_sample_image, train_sample_mask])\r\n","\r\n","  for imageBatch, maskBatch in valid_dataset.take(1):\r\n","    valid_sample_image, valid_sample_mask = imageBatch[0], maskBatch[0] \r\n","\r\n","  #####################################################################################################################\r\n","\r\n","  model = create_model(num_classes)\r\n","  model.summary()\r\n","\r\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy() \r\n","\r\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n","\r\n","  metrics = ['accuracy', meanIoU, cropIoU]\r\n","\r\n","  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\r\n","\r\n","  callbacks = get_callbacks(exp_dir)\r\n","\r\n","  history = model.fit(x=train_dataset,\r\n","              epochs=num_epochs,\r\n","              steps_per_epoch=len(train_img_data_generator),\r\n","              validation_data=valid_dataset,\r\n","              validation_steps=len(valid_img_data_generator), \r\n","              callbacks=callbacks)\r\n","  \r\n","  minLoss = min(history.history['val_loss'])\r\n","  minLossIndex = history.history['val_loss'].index(minLoss)\r\n","  loss_arr.append(minLoss)\r\n","  meanIoU_arr.append(history.history['val_meanIoU'][minLossIndex])\r\n","  \r\n","  # print metrics to file\r\n","  with open(os.path.join(exp_dir, 'historySplit' + str(loop_iteration) + '.txt'), 'w') as f:\r\n","    for key in history.history.keys():\r\n","      print(str(key), file=f)\r\n","      print(history.history[key], file=f)\r\n","\r\n","  if not enable_kfold:\r\n","    break\r\n","  \r\n","  loop_iteration += 1\r\n","\r\n","with open(os.path.join(exp_dir, 'cv_results' + '.txt'), 'w') as f2:\r\n","  print(\"avg loss = {}\".format(np.mean(loss_arr)), file=f2)\r\n","  print(\"avg meanIoU = {}\".format(np.mean(meanIoU_arr)), file=f2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxBU6H5NDWkL"},"source":["test_images = []\r\n","\r\n","base_folder = os.path.join(cwd, dataset_version, \"Test_Dev\")\r\n","\r\n","for i in range(0,8):\r\n","  if bool_arr_test[i][0]:\r\n","    team = []\r\n","    crop = []\r\n","    names = []\r\n","    base_curr = os.path.join(base_folder, bool_arr_test[i][1], bool_arr_test[i][2])\r\n","    fn_images = [x for x in os.listdir(os.path.join(base_curr, \"Images\"))]\r\n","    fn_images.sort()\r\n","    for entry in fn_images:\r\n","      names.append(entry[:-4])\r\n","\r\n","    for j in range(0, len(fn_images)):\r\n","        team.append(bool_arr_test[i][1])\r\n","        crop.append(bool_arr_test[i][2])\r\n","    for index, value in enumerate(fn_images):\r\n","      fn_images[index] = os.path.join(base_curr, \"Images\", value)\r\n","\r\n","    zipped_list = list(zip(fn_images, team, crop, names))\r\n","\r\n","    test_images += zipped_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6NuMFELiXkj"},"source":["def rle_encode(img):\r\n","    '''\r\n","    img: numpy array, 1 - foreground, 0 - background\r\n","    Returns run length as string formatted\r\n","    '''\r\n","    pixels = img.flatten()\r\n","    pixels = np.concatenate([[0], pixels, [0]])\r\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\r\n","    runs[1::2] -= runs[::2]\r\n","    return ' '.join(str(x) for x in runs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCW2Pb7L5Uk2"},"source":["# tiling utils\r\n","tile_size = 512\r\n","\r\n","def get_patches(img_arr, size=256, stride=256):\r\n","\r\n","    patches_list = []\r\n","    i_max = img_arr.shape[0] // stride\r\n","    j_max = img_arr.shape[1] // stride\r\n","\r\n","    for i in range(i_max):\r\n","        for j in range(j_max):\r\n","            patches_list.append(\r\n","                img_arr[\r\n","                    i * stride : i * stride + size,\r\n","                    j * stride : j * stride + size\r\n","                ]\r\n","            )\r\n","\r\n","    return np.stack(patches_list)\r\n","\r\n","def reconstruct_from_patches(img_arr, org_img_size, stride, size):\r\n","\r\n","    if img_arr.ndim == 3:\r\n","        img_arr = np.expand_dims(img_arr, axis=0)\r\n","\r\n","    if size is None:\r\n","        size = img_arr.shape[1]\r\n","\r\n","    if stride is None:\r\n","        stride = size\r\n","\r\n","    nm_layers = img_arr.shape[3]\r\n","\r\n","    i_max = (org_img_size[0] // stride) + 1 - (size // stride)\r\n","    j_max = (org_img_size[1] // stride) + 1 - (size // stride)\r\n","\r\n","    total_nm_images = img_arr.shape[0] // (j_max * i_max)\r\n","    nm_images = img_arr.shape[0]\r\n","\r\n","    averaging_value = size // stride\r\n","    images_list = []\r\n","    kk = 0\r\n","    for img_count in range(total_nm_images):\r\n","        img_bg = np.zeros(\r\n","            (org_img_size[0], org_img_size[1], nm_layers), dtype=img_arr[0].dtype\r\n","        )\r\n","\r\n","        for i in range(i_max):\r\n","            for j in range(j_max):\r\n","                for layer in range(nm_layers):\r\n","                    img_bg[\r\n","                        i * stride : i * stride + size,\r\n","                        j * stride : j * stride + size,\r\n","                        layer,\r\n","                    ] = img_arr[kk, :, :, layer]\r\n","\r\n","                kk += 1\r\n","\r\n","        images_list.append(img_bg)\r\n","    return np.stack(images_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qq5Gi48gzV4t"},"source":["# json generation\r\n","\r\n","import json\r\n","from PIL import Image\r\n","\r\n","submission_dict = {}\r\n","\r\n","for entry in test_images:\r\n","  \r\n","  image = Image.open(entry[0])\r\n","  width, height = image.size\r\n","\r\n","  # resize image and create crops\r\n","  image = image.resize(((width // tile_size)*tile_size, (height // tile_size)*tile_size))\r\n","  img_arr = np.array(image)\r\n","  image_crops = get_patches(img_arr, size=tile_size, stride=tile_size)\r\n","\r\n","  # prediction on each tile stacking each result\r\n","  tile_mask_list = []\r\n","  for i in range(len(image_crops)):\r\n","    tile_arr = image_crops[i]\r\n","    tile_arr = tile_arr * 1. / 255\r\n","    \r\n","    out_sigmoid = model.predict(x=tf.expand_dims(tile_arr, 0))\r\n","    \r\n","    predicted_class = tf.argmax(out_sigmoid, -1)\r\n","    predicted_class = predicted_class[0, ...]\r\n","\r\n","    tile_mask_list.append(np.array(tf.expand_dims(predicted_class, axis=-1)))\r\n","  \r\n","  mask_crops = np.stack(tile_mask_list)\r\n","\r\n","  # reconstruct and resize\r\n","  mask_reconstructed = reconstruct_from_patches(mask_crops, org_img_size=(image.height, image.width), stride=tile_size, size=tile_size)\r\n","  \r\n","  disegno = np.zeros((image.height, image.width , 3))\r\n","  disegno[np.where(mask_reconstructed[0,...,0] == 1)] = [255, 255, 255]\r\n","  disegno[np.where(mask_reconstructed[0,...,0] == 0)] = [0,0,0]\r\n","  disegno[np.where(mask_reconstructed[0,...,0] == 2)] = [216, 67, 82]\r\n","\r\n","\r\n","  imm = Image.fromarray(np.uint8(disegno)).resize((width, height))\r\n","  mask_arr = np.array(imm)\r\n","\r\n","  new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\r\n","\r\n","  new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\r\n","  new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\r\n","\r\n","  img_name = entry[3]\r\n","\r\n","  submission_dict[img_name] = {}\r\n","  submission_dict[img_name]['shape'] = new_mask_arr.shape\r\n","  submission_dict[img_name]['team'] = entry[1]\r\n","  submission_dict[img_name]['crop'] = entry[2]\r\n","  submission_dict[img_name]['segmentation'] = {}\r\n","\r\n","  # RLE encoding\r\n","  # crop\r\n","  rle_encoded_crop = rle_encode(new_mask_arr == 1)\r\n","  # weed\r\n","  rle_encoded_weed = rle_encode(new_mask_arr == 2)\r\n","\r\n","  submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\r\n","  submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\r\n","\r\n","\r\n","# Finally, save the results into the submission.json file\r\n","with open(os.path.join(exp_dir, \"submission.json\"), 'w') as f:\r\n","  json.dump(submission_dict, f)"],"execution_count":null,"outputs":[]}]}